
import collections
from io import BytesIO
import json
import numpy as np
import os
import re
from urllib.request import urlopen
import xml.etree.ElementTree as ET 
from zipfile import ZipFile
from datasets import load_dataset
from lm_eval import utils
from lm_eval.base import Task, rf
from lm_eval.metrics import mean
from fastchat.conversation import get_conv_template
import re
import ast

class MEMO_TRAP_EN(Task):
    VERSION = 0
    ID = 0
    DATASET_PATH = 'pminervini/inverse-scaling'
    DATASET_NAME = 'memo-trap'

    def download(self, data_dir=None, cache_dir=None, download_mode=None):
        # download and process dataset
        dataset = load_dataset(self.DATASET_PATH,self.DATASET_NAME, token="")
        self.dataset = collections.defaultdict(list)
        for example in dataset["data"]:
            if "Write a quote that ends in the word" in example['prompt']:
                self.dataset["test"].append(example)
        self.dataset["test"] = list(map(self._process_doc, self.dataset["test"]))

    def has_training_docs(self):
        return False

    def has_validation_docs(self):
        return False

    def has_test_docs(self):
        return True
        
    def test_docs(self):
        return self.dataset["test"]

    def _process_doc(self, doc):
        self.ID += 1
        padrao = r'"(.*?)"'
        return {
            "query": "Phrase:" + doc["prompt"].split(":")[1] + "\nComplement: " + re.findall(padrao, doc["prompt"])[0], #O que vai pro modelo
            "choices": ast.literal_eval(doc['classes']), #Suas escolhas
            "gold": doc["prompt"].split(":")[1] + ast.literal_eval(doc['classes'])[doc["answer_index"]], #resposta
            "id": self.ID
        }

    def doc_to_text(self, doc):
        return doc["query"]

    def doc_to_target(self, doc): 
        return doc["gold"]

    def construct_requests(self, doc, ctx):
        """ Uses RequestFactory to construct Requests and returns an iterable of 
        Requests which will be sent to the LM.

        :param doc:
            The document as returned from training_docs, validation_docs, or test_docs.
        :param ctx: str
            The context string, generated by fewshot_context. This includes the natural 
            language description, as well as the few shot examples, and the question
            part of the document for `doc`. 
        """
        continuation = rf.greedy_until(ctx, ['\n']) # rf -> Request factory
        return continuation

    def process_results(self, doc, results):
        gold = doc["gold"].strip()
        pred = results[0].strip()
        print("Gold: ", gold, " Pred: ", pred)
        
        # Verifica se 'gold' está presente em 'pred'
        is_gold_in_pred = gold in pred
        print("Gold is in Pred: ", is_gold_in_pred)
        
        # Acurácia será 1.0 se 'gold' estiver em 'pred', caso contrário será 0.
        acc = 1.0 if is_gold_in_pred else 0.

        results = {
            "acc": acc,
        }

        return results

    
    def higher_is_better(self):
        return {
            "acc": True,
        }

    def aggregation(self):
        def safe_mean(values):
            if len(values) == 0:
                return -1
            return mean(values)
        
        return {
            "acc": safe_mean,
        }
    
    @utils.positional_deprecated
    def fewshot_context(self, doc, num_fewshot, provide_description=None, rnd=None, description=None, conversation_template=None, prompt_as_single_user_message=False):
        """ Returns a fewshot context string that is made up of a prepended description
        (if provided), the `num_fewshot` number of examples, and an appended prompt example.

        :param doc: str
            The document as returned from training_docs, validation_docs, or test_docs.
        :param num_fewshot: int
            The number of fewshot examples to provide in the returned context string.
        :param prompt_mode: str
            The type of prompt. Please set prompt_mode as "fixed", "dynamic-random", or "dynamic-similar".
            WARNING: this is implemented only for Portuguese tasks.
        :param provide_description: bool
            Not implemented, and this option is deprecated and will be removed in a future version in favor of a different description providing method
        :param rnd: random.Random
            The pseudo-random number generator used to randomly sample examples.
            WARNING: This is currently a required arg although it's optionalized with a default `None`.
        :param description: str
            The task's description that will be prepended to the fewshot examples.
        :returns: str
            The fewshot context.
        """
        assert rnd is not None, "A `random.Random` generator argument must be provided to `rnd`"
        assert not provide_description, (
            "The `provide_description` arg will be removed in future versions. To prepend "
            "a custom description to the context, supply the corresponding string via the "
            "`description` arg."
        )
        if provide_description is not None:
            # nudge people to not specify it at all
            print("WARNING: provide_description is deprecated and will be removed in a future version in favor of description_dict")
        
        if conversation_template:
            conversation = get_conv_template(conversation_template)
            user_role, assistant_role = conversation.roles
            assert description, "Conversation prompt requires a description."
        else:
            description = description + "\n\n" if description else ""

        example = self.doc_to_text(doc)

        if num_fewshot == 0:
            labeled_examples = ""
            if conversation_template:
                conversation.append_message(user_role, description + "\n" + example)
                conversation.append_message(assistant_role, None)
        else:
            # for sets with no training docs, draw from other set *but ensure no overlap with current doc*
            if self.has_training_docs():
                # fewshotex = self.fewshot_examples(k=num_fewshot, rnd=rnd)
                ## keeping the training docs in original order (use this to fixed prompts)
                fewshotex = list(self.training_docs())[:num_fewshot]
                ## if the current doc is among the training docs, we do not use it as few-shot
                fewshotex = [ex for ex in fewshotex if doc['id'] != ex['id']]
            else:
                if self._fewshot_docs is None:
                    self._fewshot_docs = list(
                        self.validation_docs() if self.has_validation_docs() else self.test_docs()
                    )

                fewshotex = rnd.sample(self._fewshot_docs, num_fewshot + 1)

                # get rid of the doc that's the one we're evaluating, if it's in the fewshot
                fewshotex = [x for x in fewshotex if x != doc][:num_fewshot]

            labeled_examples = ''
            
            if conversation_template:
                conversation.append_message(user_role, description)
                conversation.append_message(assistant_role, "Ok, let's go.")

                for i, doc_ex in enumerate(fewshotex):
                    text = self.doc_to_text(doc_ex)
                    target = self.doc_to_target(doc_ex).strip()
                    conversation.append_message(user_role, text)
                    conversation.append_message(assistant_role, target)
                
                conversation.append_message(user_role, example)
                conversation.append_message(assistant_role, None)
            else: #Corrigir para fazer um exemplo manual
                for i, doc_ex in enumerate(fewshotex):
                    labeled_examples += f'Questão {i+1}:\n'
                    labeled_examples += self.doc_to_text(doc_ex) + self.doc_to_target(doc_ex)
                    labeled_examples += '\n##\n'
                labeled_examples += f'Questão {len(fewshotex) + 1}:\n'

        if conversation_template:
            if prompt_as_single_user_message:
                return conversation.get_prompt()
            else:
                return json.dumps(conversation.to_openai_api_messages(), ensure_ascii=False)
        else:
            return description + labeled_examples + example